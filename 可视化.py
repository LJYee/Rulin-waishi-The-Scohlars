import pandas as pd
import numpy as np
import folium
import streamlit as st
from streamlit_folium import st_folium
from pyvis.network import Network
import streamlit.components.v1 as components


# ---------------------- æ•°æ®é¢„å¤„ç†ï¼ˆåŸºäºæ‚¨çš„CSVï¼‰ ----------------------
# è¯»å–æ•°æ®
#df = pd.read_csv("/Users/ye/CHC 5904/my_streamlit_app/è¯»å–1.csv", encoding='utf-8')
df = pd.read_csv('è¯»å–1.csv', encoding='utf-8')
# ç»Ÿä¸€å­—æ®µåï¼Œä¾¿äºè°ƒç”¨
df.rename(columns={
    'å›æ¬¡': 'chapter',
    'åœ°å': 'location',
    'ç»åº¦': 'lon',
    'çº¬åº¦': 'lat',
    'åŸå¸‚å‡ºç°æ¬¡æ•°': 'loc_total_freq',  # åœ°ç‚¹æ€»å‡ºç°æ¬¡æ•°ï¼ˆåŸè¡¨å­—æ®µï¼‰
    'æ¶‰åŠä¸»è¦äººç‰©': 'characters',
    'æ´»åŠ¨ç±»å‹': 'activity_type',
    'æƒ…èŠ‚': 'plot_summary'
}, inplace=True)

# ç”ŸæˆèŠ‚ç‚¹å”¯ä¸€IDï¼ˆç”¨äºç½‘ç»œå›¾ï¼‰
# 1. åœ°ç‚¹ID
locations = df['location'].unique()
loc_id_map = {loc: f'loc_{str(i+1).zfill(3)}' for i, loc in enumerate(locations)}
df['location_id'] = df['location'].map(loc_id_map)

# 2. äººç‰©IDï¼ˆæ‹†åˆ†å¤šäººç‰©ï¼‰
all_chars = []
for chars in df['characters']:
    all_chars.extend([c.strip() for c in chars.split('ï¼Œ')])
all_chars = list(set(all_chars))  # å»é‡
char_id_map = {char: f'char_{str(i+1).zfill(3)}' for i, char in enumerate(all_chars)}

# 3. æ´»åŠ¨ç±»å‹ID
activities = df['activity_type'].unique()
act_id_map = {act: f'act_{str(i+1).zfill(3)}' for i, act in enumerate(activities)}
df['activity_type_id'] = df['activity_type'].map(act_id_map)

# ç»Ÿè®¡åœ°ç‚¹çš„ç« å›åˆ†å¸ƒï¼ˆæ¯ä¸ªåœ°ç‚¹å‡ºç°åœ¨å“ªäº›ç« å›ã€æ¯ç« å‡ºç°æ¬¡æ•°ï¼‰
loc_chapter_stats = df.groupby('location').agg({
    'chapter': lambda x: list(set(x)),  # å‡ºç°åœ¨çš„ç« å›ï¼ˆå»é‡ï¼‰
    'loc_total_freq': 'first'  # åœ°ç‚¹æ€»å‡ºç°æ¬¡æ•°
}).reset_index()
loc_chapter_stats['chapter_count'] = loc_chapter_stats['chapter'].apply(len)  # å‡ºç°åœ¨çš„ç« å›æ•°
# ç»Ÿè®¡æ¯ç« å‡ºç°æ¬¡æ•°ï¼ˆå¦‚ï¼šäº¬å¸ˆåœ¨ç¬¬10å›å‡ºç°2æ¬¡ï¼‰
loc_chapter_detail = df.groupby(['location', 'chapter']).size().reset_index(name='chapter_freq')
loc_chapter_detail['chapter_freq_str'] = loc_chapter_detail.apply(
    lambda x: f"ç¬¬{x['chapter']}å›ï¼š{x['chapter_freq']}æ¬¡", axis=1
)
loc_chapter_detail = loc_chapter_detail.groupby('location')['chapter_freq_str'].apply(list).reset_index()
# åˆå¹¶ç»Ÿè®¡ç»“æœ
loc_stats = loc_chapter_stats.merge(loc_chapter_detail, on='location')

# ---------------------- é¡µé¢è®¾è®¡ï¼ˆä¸‰ä¸ªæ ‡ç­¾é¡µï¼‰ ----------------------
tab1, tab2, tab3 = st.tabs([
    "1. åœ°ç‚¹åæ ‡åœ°å›¾", 
    "2. åŒç»´åº¦å…³è”ç½‘ç»œå›¾", 
    "3. åœ°ç‚¹-äººç‰©-æ´»åŠ¨ç»Ÿè®¡çœ‹æ¿"
])
st.title("ã€Šå„’æ—å¤–å²ã€‹å¯è§†åŒ–åˆ†æ")
st.subtitile(**"ä»¥The Scholar ç¬¬ 10-29å›ä¸ºææ–™è¿›è¡Œå¯è§†åŒ–" \
"åˆ†æåœ°ç‚¹ä¸äººç‰©æ´»åŠ¨ä¹‹é—´çš„å…³è”ï¼Œæ¢ç©¶ä¸åŒåœ°ç‚¹çš„äººç‰©æ´»åŠ¨ç‰¹å¾")
# ---------------------- æ ‡ç­¾é¡µ1ï¼šåœ°ç‚¹åæ ‡åœ°å›¾ ----------------------
with tab1:
    st.title("ã€Šå„’æ—å¤–å²ã€‹åœ°ç‚¹åæ ‡åœ°å›¾")
    
    # ä¾§è¾¹æ ç­›é€‰å™¨ï¼ˆåŸºäºrenameåçš„å­—æ®µï¼šchapter/location/activity_typeï¼‰
    st.sidebar.header("åœ°å›¾ç­›é€‰æ¡ä»¶")
    # 1. åœ°ç‚¹ç­›é€‰ï¼ˆç”¨renameåçš„locationå­—æ®µï¼‰
    selected_locs = st.sidebar.multiselect(
        "é€‰æ‹©åœ°ç‚¹", 
        df['location'].unique(), 
        default=df['location'].unique(),  # é»˜è®¤å…¨é€‰
        key="tab1_location"   
    )
    # 2. æ´»åŠ¨ç±»å‹ç­›é€‰ï¼ˆç”¨renameåçš„activity_typeå­—æ®µï¼‰
    selected_acts = st.sidebar.multiselect(
        "é€‰æ‹©æ´»åŠ¨ç±»å‹", 
        df['activity_type'].unique(), 
        default=df['activity_type'].unique(),
        key="tab1_activity" 
    )

    # 3. ç« å›èŒƒå›´ç­›é€‰ï¼ˆç”¨renameåçš„chapterå­—æ®µï¼Œç¡®ä¿æ•´æ•°ç±»å‹ï¼‰
    min_chapter = int(df['chapter'].min())
    max_chapter = int(df['chapter'].max())
    selected_chapters = st.sidebar.slider(
        "é€‰æ‹©ç« å›èŒƒå›´", 
        min_value=min_chapter, 
        max_value=max_chapter, 
        value=(min_chapter, max_chapter)
    )
    
    # åº”ç”¨ç­›é€‰æ¡ä»¶ï¼ˆåŸºäºrenameåçš„å­—æ®µï¼‰
    filtered_df = df[
        (df['location'].isin(selected_locs)) &
        (df['activity_type'].isin(selected_acts)) &
        (df['chapter'] >= selected_chapters[0]) &
        (df['chapter'] <= selected_chapters[1])
    ]
    
    if filtered_df.empty:
        st.warning("æš‚æ— ç¬¦åˆæ¡ä»¶çš„æ•°æ®ï¼Œè¯·è°ƒæ•´ç­›é€‰æ¡ä»¶ï¼")
    else:
        # 1. åˆ›å»ºåœ°å›¾ï¼ˆä¸­å›½ä¸­å¿ƒç‚¹ï¼‰
        m = folium.Map(location=[35.8617, 104.1954], zoom_start=4, tiles="CartoDB positron")
        
        # 2. ä¸ºæ¯ä¸ªåœ°ç‚¹æ·»åŠ æ ‡è®°ï¼ˆæ ¸å¿ƒï¼šç”¨renameåçš„loc_total_freqå­—æ®µç»Ÿè®¡ï¼‰
        for loc in filtered_df['location'].unique():
            # æå–å½“å‰åœ°ç‚¹çš„ç­›é€‰æ•°æ®ï¼ˆå«å¤šæ´»åŠ¨æ ‡ç­¾è¡Œï¼‰
            loc_filtered_data = filtered_df[filtered_df['location'] == loc]
            loc_base_data = loc_filtered_data.iloc[0]  # å–1è¡Œè·å–ç»çº¬åº¦/æƒ…èŠ‚ç­‰åŸºç¡€ä¿¡æ¯
            
            # ---------------------- å…³é”®ç»Ÿè®¡ï¼ˆåŸºäºloc_total_freqå­—æ®µï¼‰ ----------------------
            # â‘  æ€»å‡ºç°æ¬¡æ•°ï¼šæŒ‰â€œåœ°ç‚¹+ç« å›â€å»é‡åï¼Œæ±‚å’Œloc_total_freqï¼ˆé¿å…å¤šæ ‡ç­¾è¡Œé‡å¤ç´¯åŠ ï¼‰
            # å»é‡ï¼šåŒä¸€åœ°ç‚¹åŒä¸€ç« å›åªä¿ç•™1è¡Œï¼ˆé˜²æ­¢å¤šæ´»åŠ¨æ ‡ç­¾è¡Œé‡å¤ç»Ÿè®¡æ¬¡æ•°ï¼‰
            loc_chapter_unique = loc_filtered_data[['chapter', 'loc_total_freq']].drop_duplicates()
            total_freq = int(loc_chapter_unique['loc_total_freq'].sum())  # æ±‚å’Œå¾—åˆ°æ€»å‡ºç°æ¬¡æ•°
            
            # â‘¡ æ¯ç« å‡ºç°æ¬¡æ•°ï¼šè¯»å–å»é‡åçš„loc_total_freqï¼ˆåŸè¡¨é¢„è®¾çš„æ¯å›æ¬¡æ•°ï¼‰
            chapter_freq_dict = dict(zip(loc_chapter_unique['chapter'], loc_chapter_unique['loc_total_freq']))
            chapter_freq_str = [f"ç¬¬{int(chap)}å›ï¼š{int(freq)}æ¬¡" for chap, freq in chapter_freq_dict.items()]
            
            # â‘¢ æ¶‰åŠç« å›ç»Ÿè®¡ï¼ˆå»é‡åï¼‰
            chapter_list = sorted(loc_chapter_unique['chapter'].tolist())  # æ’åºç« å›
            chapter_count = len(chapter_list)  # æ¶‰åŠç« å›æ•°
            
            # ---------------------- æ´»åŠ¨ç±»å‹ç»Ÿè®¡ï¼ˆä¿ç•™å¤šæ ‡ç­¾ï¼‰ ----------------------
            act_freq_dict = loc_filtered_data['activity_type'].value_counts().to_dict()
            act_freq_str = "\n".join([f"{act}ï¼š{int(freq)}æ¬¡" for act, freq in act_freq_dict.items()])
            main_act = max(act_freq_dict, key=act_freq_dict.get) if act_freq_dict else "å…¶ä»–"
            
            # ---------------------- æ ‡è®°æ ·å¼ï¼ˆé¢œè‰²+å¤§å°ï¼‰ ----------------------
            # æ´»åŠ¨ç±»å‹é¢œè‰²æ˜ å°„ï¼ˆé˜²KeyErrorï¼‰
            act_color_map = {
                 "å®˜åœºä»»èŒ": "#E67E22",  # æ©™è‰²
                 "å®¶åº­ç”Ÿæ´»": "#EEAA9C",  # ç²‰è‰²
                 "ç§‘ä¸¾å¤‡è€ƒ": "#3498DB",  # è“è‰²
                 "å•†ä¸šç»æµ": "#8E44AD",  # ç´«è‰²
                 "ç¤¾äº¤å¾€æ¥": "#F39C12",  # é»„è‰²
                 "ç‰¹æ®Šå˜æ•…": "#E74C3C",  # çº¢è‰²
                 "æ–‡äººé›…é›†": "#b9dec9",  # æ·¡ç»¿
                 "å…¶ä»–": "#95A5A6"      # ç°è‰²ï¼ˆå…œåº•ï¼‰
            }
            marker_color = act_color_map.get(main_act, act_color_map["å…¶ä»–"])
            
            # æ ‡è®°å¤§å°ï¼šæŒ‰æ€»å‡ºç°æ¬¡æ•°æ¯”ä¾‹è®¡ç®—ï¼ˆ12-32åƒç´ ï¼Œé¿å…è¿‡å¤§/è¿‡å°ï¼‰
            # å…ˆè®¡ç®—ç­›é€‰åæ‰€æœ‰åœ°ç‚¹çš„æœ€å¤§æ€»æ¬¡æ•°
            max_total_freq = max([
                int(filtered_df[filtered_df['location'] == temp_loc][['chapter', 'loc_total_freq']].drop_duplicates()['loc_total_freq'].sum())
                for temp_loc in filtered_df['location'].unique()
            ])
            marker_radius = 12 + (total_freq / max_total_freq) * 20
            
            # ---------------------- å¤„ç†ç©ºå€¼ï¼ˆé¿å…æƒ…èŠ‚ä¸ºNaNæŠ¥é”™ï¼‰ ----------------------
            plot_content = loc_base_data['plot_summary'][:120] if pd.notna(loc_base_data['plot_summary']) else "æ— ç›¸å…³æƒ…èŠ‚"
            
            # ---------------------- æ·»åŠ åœ°å›¾æ ‡è®°ï¼ˆhover+å¼¹çª—ï¼‰ ----------------------
            folium.CircleMarker(
                location=[loc_base_data['lat'], loc_base_data['lon']],  # foliumè¦æ±‚ï¼šçº¬åº¦åœ¨å‰ï¼Œç»åº¦åœ¨å
                radius=marker_radius,
                color=marker_color,
                fill=True,
                fill_color=marker_color,
                fill_opacity=0.8,
                # Hoveræç¤ºï¼šæ ¸å¿ƒä¿¡æ¯å¿«é€Ÿé¢„è§ˆ
                tooltip=f"""
                    <b>{loc}</b><br>
                    æ€»å‡ºç°æ¬¡æ•°ï¼š{total_freq}æ¬¡<br>
                    æ¶‰åŠç« å›ï¼š{chapter_count}å›<br>
                    ä¸»è¦æ´»åŠ¨ï¼š{main_act}
                """,
                # ç‚¹å‡»å¼¹çª—ï¼šè¯¦ç»†ä¿¡æ¯ï¼ˆå«äººç‰©ã€æƒ…èŠ‚ï¼‰
                popup=folium.Popup(f"""
                    <div style='width:280px; font-size:14px; line-height:1.5'>
                        <h4 style='margin:0; color:{marker_color}; font-size:16px'>{loc}</h4>
                        
                        <p><b>1. å‡ºç°ç»Ÿè®¡</b></p>
                        <p>æ€»å‡ºç°æ¬¡æ•°ï¼š{total_freq}æ¬¡</p>
                        <p>æ¶‰åŠç« å›ï¼š{chapter_count}å›ï¼ˆ{', '.join(map(str, map(int, chapter_list)))}ï¼‰</p>
                        <p>æ¯ç« å‡ºç°æ¬¡æ•°ï¼š<br>{'<br>'.join(chapter_freq_str)}</p>
                        
                        <p><b>2. æ ¸å¿ƒä¿¡æ¯</b></p>
                        <p>æ¶‰åŠä¸»è¦äººç‰©ï¼š{loc_base_data['characters'] if pd.notna(loc_base_data['characters']) else "æ— "}</p>
                        <p>ä¸»è¦æ´»åŠ¨ç±»å‹ï¼š{main_act}</p>
                        
                        <p><b>3. æƒ…èŠ‚ç¤ºä¾‹</b></p>
                        <p>{plot_content}...</p>
                    </div>
                """, max_width=300)
            ).add_to(m)
        
        # 3. æ¸²æŸ“åœ°å›¾ï¼ˆå æ»¡é¡µé¢å®½åº¦ï¼Œé«˜åº¦700pxé€‚é…å±å¹•ï¼‰
        st_folium(m, width="100%", height=700)
        
        # 4. ç­›é€‰ç»“æœç»Ÿè®¡è¡¨æ ¼ï¼ˆåŸºäºloc_total_freqå­—æ®µï¼Œä¸åœ°å›¾é€»è¾‘ä¸€è‡´ï¼‰
        st.subheader("ç­›é€‰ç»“æœç»Ÿè®¡ï¼ˆåœ°ç‚¹ç»´åº¦ï¼‰")
        result_stats = []
        for loc in filtered_df['location'].unique():
            loc_data = filtered_df[filtered_df['location'] == loc]
            # æŒ‰â€œç« å›+loc_total_freqâ€å»é‡åç»Ÿè®¡
            loc_chapter_unique = loc_data[['chapter', 'loc_total_freq']].drop_duplicates()
            total_freq = int(loc_chapter_unique['loc_total_freq'].sum())
            chapter_list = sorted(loc_chapter_unique['chapter'].tolist())
            chapter_str = f"{len(chapter_list)}å›ï¼ˆ{', '.join(map(str, map(int, chapter_list)))}ï¼‰"
            # æ´»åŠ¨ç±»å‹ç»Ÿè®¡
            act_freq = loc_data['activity_type'].value_counts().to_dict()
            act_str = "\n".join([f"{act}ï¼š{int(freq)}æ¬¡" for act, freq in act_freq.items()])
            # ä¸»è¦äººç‰©
            main_char = loc_data['characters'].value_counts().index[0] if len(loc_data['characters'].dropna()) > 0 else "æ— "
            
            result_stats.append({
                'åºå·': len(result_stats) + 1,
                'åœ°ç‚¹': loc,
                'æ€»å‡ºç°æ¬¡æ•°': total_freq,
                'æ¶‰åŠç« å›': chapter_str,
                'ä¸»è¦æ¶‰åŠäººç‰©': main_char,
                'æ´»åŠ¨ç±»å‹ç»Ÿè®¡': act_str
            })
        
        # æ˜¾ç¤ºè¡¨æ ¼ï¼ˆåºå·è®¾ä¸ºç´¢å¼•ï¼Œæå‡å¯è¯»æ€§ï¼‰
        result_df = pd.DataFrame(result_stats)
        st.dataframe(result_df.set_index('åºå·'), height=400)

# ---------------------- æ ‡ç­¾é¡µ2ï¼šäººç‰©-åœ°ç‚¹-æ´»åŠ¨ç±»å‹ä¸‰èŠ‚ç‚¹å›¾ ----------------------
with tab2:
    st.title("ã€Šå„’æ—å¤–å²ã€‹åŒç»´åº¦å…³è”ç½‘ç»œå›¾")
    st.markdown("### ä¸€ã€äººç‰©-åœ°ç‚¹å…³è”å›¾è°±")
    
    # ä¾§è¾¹æ ç­›é€‰ï¼šæ§åˆ¶ç½‘ç»œå›¾æ•°æ®èŒƒå›´
    st.sidebar.header("ç½‘ç»œå›¾ç­›é€‰æ¡ä»¶")
    # 1. åœ°ç‚¹ç­›é€‰ï¼ˆæ”¯æŒå¤šé€‰ï¼Œé»˜è®¤å…¨é€‰ï¼‰
    selected_locs_net = st.sidebar.multiselect(
        "é€‰æ‹©å…³è”åœ°ç‚¹ï¼ˆé»˜è®¤å…¨é€‰ï¼‰",
        df['location'].unique(),
        default=df['location'].unique(),
        key="net_location_filter"
    )
    # 2. äººç‰©ç­›é€‰ï¼ˆæ”¯æŒå¤šé€‰ï¼Œé»˜è®¤å…¨é€‰ï¼Œå¤„ç†ç©ºå€¼ï¼‰
    all_chars = list(set([
        c.strip() for chars in df['characters'].dropna() 
        for c in chars.split('ï¼Œ') if c.strip()
    ]))
    selected_chars_net = st.sidebar.multiselect(
        "é€‰æ‹©å…³è”äººç‰©ï¼ˆé»˜è®¤å…¨é€‰ï¼‰",
        sorted(all_chars),  # æŒ‰å­—æ¯æ’åºï¼Œä¾¿äºé€‰æ‹©
        default=sorted(all_chars),
        key="net_char_filter"
    )
    # 3. ç« å›èŒƒå›´ç­›é€‰ï¼ˆæ§åˆ¶æ•°æ®æ—¶é—´èŒƒå›´ï¼‰
    selected_chapters_net = st.sidebar.slider(
        "é€‰æ‹©ç« å›èŒƒå›´",
        min_value=int(df['chapter'].min()),
        max_value=int(df['chapter'].max()),
        value=(int(df['chapter'].min()), int(df['chapter'].max())),
        key="net_chapter_slider"
    )
    
    # ç¬¬ä¸€æ­¥ï¼šç­›é€‰æ•°æ®ï¼ˆæŒ‰ç« å›ã€åœ°ç‚¹ã€äººç‰©ï¼‰
    net_df = df[
        (df['chapter'] >= selected_chapters_net[0]) &
        (df['chapter'] <= selected_chapters_net[1]) &
        (df['location'].isin(selected_locs_net))
    ].copy()
    
    # å¤„ç†äººç‰©æ•°æ®ï¼šæ‹†åˆ†å¤šäººç‰©ï¼Œä»…ä¿ç•™é€‰ä¸­çš„äººç‰©
    def filter_chars(char_str):
        """æ‹†åˆ†äººç‰©å­—ç¬¦ä¸²ï¼Œä¿ç•™é€‰ä¸­çš„äººç‰©"""
        if pd.isna(char_str):
            return []
        return [c.strip() for c in char_str.split('ï¼Œ') if c.strip() in selected_chars_net]
    
    net_df['filtered_chars'] = net_df['characters'].apply(filter_chars)
    # è¿‡æ»¤æ‰æ— é€‰ä¸­äººç‰©çš„è¡Œ
    net_df = net_df[net_df['filtered_chars'].apply(len) > 0].reset_index(drop=True)
    
    if net_df.empty:
        st.warning("æš‚æ— ç¬¦åˆæ¡ä»¶çš„äººç‰©-åœ°ç‚¹å…³è”æ•°æ®ï¼Œè¯·è°ƒæ•´ç­›é€‰æ¡ä»¶ï¼")
    else:
        # ç¬¬äºŒæ­¥ï¼šç»Ÿè®¡èŠ‚ç‚¹é¢‘æ¬¡ï¼ˆç”¨äºåŠ¨æ€è°ƒæ•´èŠ‚ç‚¹å¤§å°ï¼‰
        # 1. åœ°ç‚¹é¢‘æ¬¡ï¼šæŒ‰loc_total_freqæ±‚å’Œï¼ˆæ€»å‡ºç°æ¬¡æ•°ï¼‰
        loc_freq = net_df.groupby('location')['loc_total_freq'].sum().reset_index()
        loc_freq.columns = ['node', 'freq']
        loc_freq['type'] = 'åœ°ç‚¹'  # æ ‡è®°èŠ‚ç‚¹ç±»å‹
        
        # 2. äººç‰©é¢‘æ¬¡ï¼šç»Ÿè®¡äººç‰©åœ¨ç­›é€‰æ•°æ®ä¸­çš„å‡ºç°æ¬¡æ•°
        char_freq_list = []
        for _, row in net_df.iterrows():
            for char in row['filtered_chars']:
                char_freq_list.append({'char': char, 'loc': row['location']})
        char_freq_df = pd.DataFrame(char_freq_list)
        char_freq = char_freq_df['char'].value_counts().reset_index()
        char_freq.columns = ['node', 'freq']
        char_freq['type'] = 'äººç‰©'  # æ ‡è®°èŠ‚ç‚¹ç±»å‹
        
        # åˆå¹¶èŠ‚ç‚¹é¢‘æ¬¡ï¼Œç»Ÿä¸€å¤„ç†
        node_freq = pd.concat([loc_freq, char_freq], ignore_index=True)
        # èŠ‚ç‚¹å¤§å°æ˜ å°„ï¼šé¢‘æ¬¡â†’å¤§å°ï¼ˆæœ€å°20ï¼Œæœ€å¤§80ï¼Œé¿å…è¿‡å°/è¿‡å¤§ï¼‰
        min_size = 20
        max_size = 80
        node_freq['size'] = node_freq['freq'].apply(
            lambda x: min_size + (max_size - min_size) * (x - node_freq['freq'].min()) / 
            (node_freq['freq'].max() - node_freq['freq'].min()) if node_freq['freq'].max() > node_freq['freq'].min() else 30
        )
    
        # ç¬¬ä¸‰æ­¥ï¼šæ„å»ºäººç‰©-åœ°ç‚¹åŒèŠ‚ç‚¹ç½‘ç»œ
        from pyvis.network import Network
        
        # åˆå§‹åŒ–ç½‘ç»œå›¾ï¼ˆè®¾ç½®å°ºå¯¸ã€èƒŒæ™¯è‰²ï¼Œå…³é—­notebookæ¨¡å¼ï¼‰
        net = Network(
            directed=False,  # æ— å‘å›¾ï¼ˆäººç‰©-åœ°ç‚¹æ˜¯åŒå‘å…³è”ï¼‰
            notebook=False,
            height="800px",  # é«˜åº¦é€‚é…é¡µé¢
            width="100%",    # å®½åº¦å æ»¡é¡µé¢
            bgcolor="#f8f9fa",  # æµ…ç°èƒŒæ™¯ï¼Œæå‡è§†è§‰èˆ’é€‚åº¦
            font_color="#333333"  # å­—ä½“é¢œè‰²ï¼šæ·±ç°ï¼Œé¿å…åˆºçœ¼
        )
        
        # 1. æ·»åŠ èŠ‚ç‚¹ï¼ˆå…ˆæ·»åŠ åœ°ç‚¹ï¼Œå†æ·»åŠ äººç‰©ï¼Œé¿å…é‡å ï¼‰
        # åœ°ç‚¹èŠ‚ç‚¹ï¼šè“è‰²ï¼Œæ ‡ç­¾æ˜¾ç¤ºâ€œåœ°ç‚¹ï¼ˆé¢‘æ¬¡ï¼‰â€
        for _, row in loc_freq.iterrows():
            loc = row['node']
            freq = row['freq']
            size = node_freq[node_freq['node'] == loc]['size'].iloc[0]
            # Hoveræç¤ºï¼šæ˜¾ç¤ºåœ°ç‚¹å…³è”çš„æ‰€æœ‰äººç‰©
            related_chars = char_freq_df[char_freq_df['loc'] == loc]['char'].unique()
            title = f"åœ°ç‚¹ï¼š{loc}\næ€»å‡ºç°æ¬¡æ•°ï¼š{freq}æ¬¡\nå…³è”äººç‰©ï¼š{', '.join(related_chars) if len(related_chars) > 0 else 'æ— '}"
            net.add_node(
                n_id=f"loc_{loc}",  # èŠ‚ç‚¹IDå‰ç¼€ï¼šloc_ï¼Œé¿å…ä¸äººç‰©IDå†²çª
                label=f"{loc}\nï¼ˆ{freq}æ¬¡ï¼‰",  # æ ‡ç­¾ï¼šåœ°ç‚¹+é¢‘æ¬¡
                size=size,
                color="#652D2D",  # åŒºåˆ†åœ°ç‚¹èŠ‚ç‚¹
                title=title,  # Hoveræç¤º
                font={"size": 12, "weight": "bold"}  # å­—ä½“åŠ ç²—ï¼Œæå‡è¾¨è¯†åº¦
            )
        
        # äººç‰©èŠ‚ç‚¹ï¼šæ©™è‰²ï¼Œæ ‡ç­¾æ˜¾ç¤ºâ€œäººç‰©ï¼ˆé¢‘æ¬¡ï¼‰â€
        for _, row in char_freq.iterrows():
            char = row['node']
            freq = row['freq']
            size = node_freq[node_freq['node'] == char]['size'].iloc[0]
            # Hoveræç¤ºï¼šæ˜¾ç¤ºäººç‰©å…³è”çš„æ‰€æœ‰åœ°ç‚¹
            related_locs = char_freq_df[char_freq_df['char'] == char]['loc'].unique()
            title = f"äººç‰©ï¼š{char}\nå…³è”åœ°ç‚¹æ•°ï¼š{freq}ä¸ª\nå…³è”åœ°ç‚¹ï¼š{', '.join(related_locs) if len(related_locs) > 0 else 'æ— '}"
            net.add_node(
                n_id=f"char_{char}",  # èŠ‚ç‚¹IDå‰ç¼€ï¼šchar_ï¼Œé¿å…ä¸åœ°ç‚¹IDå†²çª
                label=f"{char}\nï¼ˆ{freq}ä¸ªåœ°ç‚¹ï¼‰",  # æ ‡ç­¾ï¼šäººç‰©+å…³è”åœ°ç‚¹æ•°
                size=size,
                color="#DAB6B2",  # åŒºåˆ†äººç‰©èŠ‚ç‚¹
                title=title,  # Hoveræç¤º
                font={"size": 12, "weight": "bold"}
            )
        
        # 2. æ·»åŠ è¾¹ï¼ˆäººç‰©-åœ°ç‚¹å…³è”ï¼Œä»…æ·»åŠ ä¸€æ¬¡ï¼Œé¿å…é‡å¤ï¼‰
        edge_set = set()  # ç”¨é›†åˆå»é‡ï¼Œé¿å…åŒä¸€äººç‰©-åœ°ç‚¹æ·»åŠ å¤šæ¡è¾¹
        for _, row in net_df.iterrows():
            loc = row['location']
            loc_node_id = f"loc_{loc}"
            for char in row['filtered_chars']:
                char_node_id = f"char_{char}"
                # è¾¹IDï¼šæŒ‰â€œäººç‰©-åœ°ç‚¹â€æ’åºï¼Œç¡®ä¿ï¼ˆA-Bï¼‰å’Œï¼ˆB-Aï¼‰æ˜¯åŒä¸€æ¡è¾¹
                edge_key = tuple(sorted([char_node_id, loc_node_id]))
                if edge_key not in edge_set:
                    edge_set.add(edge_key)
                    # è¾¹çš„hoveræç¤ºï¼šæ˜¾ç¤ºå…³è”çš„ç« å›å’Œæ´»åŠ¨ç±»å‹
                    chapters = sorted(net_df[(net_df['location'] == loc) & (net_df['filtered_chars'].apply(lambda x: char in x))]['chapter'].unique())
                    acts = net_df[(net_df['location'] == loc) & (net_df['filtered_chars'].apply(lambda x: char in x))]['activity_type'].unique()
                    edge_title = f"å…³è”ï¼š{char} â†” {loc}\næ¶‰åŠç« å›ï¼š{', '.join(map(str, chapters))}\nå‚ä¸æ´»åŠ¨ï¼š{', '.join(acts)}"
                    net.add_edge(
                        char_node_id,
                        loc_node_id,
                        color="#9AA0A6",  # ç°è‰²è¾¹ï¼šä¸æŠ¢èŠ‚ç‚¹è§†è§‰ç„¦ç‚¹
                        width=2,  # è¾¹å®½åº¦ï¼šé€‚ä¸­ï¼Œä¾¿äºè¯†åˆ«
                        title=edge_title,  # Hoveræç¤ºï¼šæ˜¾ç¤ºå…³è”ç»†èŠ‚
                        smooth=True  # å¹³æ»‘è¾¹ï¼šæå‡å›¾è°±ç¾è§‚åº¦
                    )
        
        # ç¬¬å››æ­¥ï¼šä¼˜åŒ–å›¾è°±å¸ƒå±€ä¸äº¤äº’
        # 1. è®¾ç½®ç‰©ç†å¼•æ“å‚æ•°ï¼ˆé¿å…èŠ‚ç‚¹è¿‡åº¦é‡å ï¼‰
        net.barnes_hut(
            gravity=-3000,  # å¼•åŠ›ï¼šè´Ÿå€¼ï¼Œè®©èŠ‚ç‚¹åˆ†æ•£
            central_gravity=0.3,  # ä¸­å¿ƒå¼•åŠ›ï¼šé€‚ä¸­ï¼Œé¿å…èŠ‚ç‚¹åç¦»ä¸­å¿ƒ
            spring_length=200,  # å¼¹ç°§é•¿åº¦ï¼šæ§åˆ¶èŠ‚ç‚¹é—´è·
            spring_strength=0.05,  # å¼¹ç°§å¼ºåº¦ï¼šé¿å…èŠ‚ç‚¹è¿‡è¿‘
            damping=0.4  # é˜»å°¼ï¼šæ§åˆ¶èŠ‚ç‚¹è¿åŠ¨é€Ÿåº¦ï¼Œé¿å…éœ‡è¡
        )
        
        # 2. æ˜¾ç¤ºå…³é”®è°ƒèŠ‚æŒ‰é’®ï¼ˆä»…ä¿ç•™ç‰©ç†å‚æ•°ã€èŠ‚ç‚¹ã€è¾¹ï¼Œé¿å…å†—ä½™ï¼‰
        net.show_buttons(["physics", "nodes", "edges"])
        
        # 3. ä¿å­˜å›¾è°±åˆ°æœ¬åœ°ï¼ˆé€‚é…macOSè·¯å¾„ï¼Œé¿å…/mnté—®é¢˜ï¼‰
        # ğŸ”´ æ›¿æ¢ä¿å­˜å’Œæ˜¾ç¤ºé€»è¾‘ï¼šç”¨Streamlitä¸´æ—¶ç›®å½•+components.v1.htmlåŠ è½½
        import streamlit.components.v1 as components
        import os
        import tempfile

# ä¿å­˜å›¾è°±åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as f:
           net.save_graph(f.name)
           temp_path = f.name

        #import os
        #net_save_path = "/Users/ye/Desktop/äººç‰©åœ°ç‚¹åŒèŠ‚ç‚¹ç½‘ç»œå›¾.html"
        #net.save_graph(net_save_path)
        
        # 4. åœ¨Streamlitä¸­æ˜¾ç¤ºå›¾è°±ï¼ˆç”¨iframeåµŒå…¥ï¼Œæ”¯æŒäº¤äº’ï¼‰
        st.subheader("äººç‰©-åœ°ç‚¹å…³è”å›¾è°±")
        with open(temp_path, "r", encoding="utf-8") as f:
             html_content = f.read()
        components.html(html_content, width="100%", height=800, scrolling=True)

# 
        # 5. å›¾è°±è¯´æ˜ï¼ˆå¸®åŠ©ç”¨æˆ·ç†è§£ï¼‰
        #st.info("""
        #    ğŸ“Œ å›¾è°±è¯´æ˜ï¼š
       #     1. è“è‰²èŠ‚ç‚¹ï¼šåœ°ç‚¹ï¼ˆå¤§å°=åœ°ç‚¹æ€»å‡ºç°æ¬¡æ•°ï¼ŒHoveræŸ¥çœ‹å…³è”äººç‰©ï¼‰ï¼›
        #    2. æ©™è‰²èŠ‚ç‚¹ï¼šäººç‰©ï¼ˆå¤§å°=äººç‰©å…³è”åœ°ç‚¹æ•°ï¼ŒHoveræŸ¥çœ‹å…³è”åœ°ç‚¹ï¼‰ï¼›
        #   3. ç°è‰²è¾¹ï¼šäººç‰©-åœ°ç‚¹å…³è”ï¼ˆHoveræŸ¥çœ‹æ¶‰åŠç« å›å’Œæ´»åŠ¨ç±»å‹ï¼‰ï¼›
         # 4. å³ä¾§è°ƒèŠ‚æŒ‰é’®ï¼šå¯è°ƒæ•´èŠ‚ç‚¹å¤§å°ã€è¾¹å®½åº¦ã€å›¾è°±å¸ƒå±€ç­‰å‚æ•°ã€‚
       # """)
        st.caption("æ·±çº¢è‰²=åœ°ç‚¹ï¼ˆå¤§å°=æ€»å‡ºç°æ¬¡æ•°ï¼‰" \
                   "æµ…çº¢è‰²=äººç‰©è§’è‰²" 
        )
    
    st.markdown("### äºŒã€åœ°ç‚¹-æ´»åŠ¨ç±»å‹å…³è”å›¾è°±")  # ç¬¬äºŒä¸ªå›¾è°±æ ‡é¢˜
    
    # 1. åœ°ç‚¹-æ´»åŠ¨å›¾è°±ï¼šæ•°æ®ç­›é€‰ï¼ˆå¤ç”¨ä¾§è¾¹æ çš„â€œåœ°ç‚¹â€â€œç« å›â€ç­›é€‰ï¼Œæ–°å¢â€œæ´»åŠ¨ç±»å‹â€ç­›é€‰ï¼‰
    # æ–°å¢æ´»åŠ¨ç±»å‹ç­›é€‰ï¼ˆä»…ç”¨äºåœ°ç‚¹-æ´»åŠ¨å›¾è°±ï¼Œæ”¾åœ¨ä¾§è¾¹æ äººç‰©ç­›é€‰ä¸‹æ–¹ï¼‰
    selected_acts_net = st.sidebar.multiselect(
        "é€‰æ‹©å…³è”æ´»åŠ¨ç±»å‹ï¼ˆé»˜è®¤å…¨é€‰ï¼‰",
        df['activity_type'].unique(),
        default=df['activity_type'].unique(),
        key="net_act_filter"
    )
    # åº”ç”¨ç­›é€‰ï¼ˆåœ°ç‚¹ã€ç« å›ã€æ´»åŠ¨ç±»å‹ï¼‰
    net_df_loc_act = df[
        (df['chapter'] >= selected_chapters_net[0]) &
        (df['chapter'] <= selected_chapters_net[1]) &
        (df['location'].isin(selected_locs_net)) &
        (df['activity_type'].isin(selected_acts_net))
    ].copy()
    
    # 2. åœ°ç‚¹-æ´»åŠ¨å›¾è°±ï¼šç”Ÿæˆä¸æ˜¾ç¤º
    if net_df_loc_act.empty:
        st.warning("æš‚æ— ç¬¦åˆæ¡ä»¶çš„åœ°ç‚¹-æ´»åŠ¨å…³è”æ•°æ®ï¼Œè¯·è°ƒæ•´ç­›é€‰æ¡ä»¶ï¼")
    else:
        # åˆå§‹åŒ–åœ°ç‚¹-æ´»åŠ¨ç½‘ç»œå›¾
        net_loc_act = Network(
            directed=False, height="600px", width="100%",
            bgcolor="#f8f9fa", font_color="#333333"
        )
        
        # â‘  æ·»åŠ åœ°ç‚¹èŠ‚ç‚¹ï¼ˆç»¿è‰²ï¼Œå¤§å°=æ€»å‡ºç°æ¬¡æ•°ï¼‰
        loc_stats_act = net_df_loc_act.groupby('location').agg({
            'loc_total_freq': 'sum',
            'activity_type': lambda x: x.value_counts().to_dict()
        }).reset_index()
        for _, row in loc_stats_act.iterrows():
            loc = row['node'] if 'node' in row else row['location']  # å…¼å®¹å­—æ®µå
            loc = row['location']
            total_freq = row['loc_total_freq']
            # Hoveræç¤ºï¼šåœ°ç‚¹+æ€»æ¬¡æ•°+å…³è”æ´»åŠ¨
            act_str = ", ".join([f"{act}ï¼ˆ{freq}æ¬¡ï¼‰" for act, freq in row['activity_type'].items()])
            net_loc_act.add_node(
                f"loc_act_{loc}",  # å‰ç¼€åŒºåˆ†ï¼Œé¿å…ä¸äººç‰©-åœ°ç‚¹å›¾è°±IDå†²çª
                label=f"{loc}\nï¼ˆ{total_freq}æ¬¡ï¼‰",
                size=25 + total_freq * 2,  # å¤§å°éšæ€»æ¬¡æ•°å˜åŒ–
                color="#1F3059",  # æ·±ç´«è‰²=åœ°ç‚¹
                title=f"åœ°ç‚¹ï¼š{loc}\næ€»å‡ºç°æ¬¡æ•°ï¼š{total_freq}æ¬¡\nå…³è”æ´»åŠ¨ï¼š{act_str}"
            )
        
        # â‘¡ æ·»åŠ æ´»åŠ¨ç±»å‹èŠ‚ç‚¹ï¼ˆç´«è‰²ï¼Œå¤§å°=å…³è”åœ°ç‚¹æ•°ï¼‰
        act_stats_loc = net_df_loc_act.groupby('activity_type').agg({
            'location': lambda x: list(set(x)),
            'loc_total_freq': 'sum'
        }).reset_index()
        act_stats_loc['related_loc_count'] = act_stats_loc['location'].apply(len)
        for _, row in act_stats_loc.iterrows():
            act = row['activity_type']
            loc_count = row['related_loc_count']
            # Hoveræç¤ºï¼šæ´»åŠ¨+å…³è”åœ°ç‚¹æ•°+å…·ä½“åœ°ç‚¹
            loc_str = ", ".join(row['location'])
            net_loc_act.add_node(
                f"act_loc_{act}",  # å‰ç¼€åŒºåˆ†ï¼Œé¿å…IDå†²çª
                label=f"{act}\nï¼ˆ{loc_count}åœ°ï¼‰",
                size=20 + loc_count * 3,  # å¤§å°éšå…³è”åœ°ç‚¹æ•°å˜åŒ–
                color="#a6c1ed",  # ç´«è‰²=æ´»åŠ¨ç±»å‹
                title=f"æ´»åŠ¨ç±»å‹ï¼š{act}\nå…³è”åœ°ç‚¹æ•°ï¼š{loc_count}ä¸ª\næ¶‰åŠåœ°ç‚¹ï¼š{loc_str}"
            )
        
        # â‘¢ æ·»åŠ åœ°ç‚¹-æ´»åŠ¨è¾¹ï¼ˆç°è‰²ï¼Œç²—ç»†=æ´»åŠ¨åœ¨è¯¥åœ°ç‚¹çš„é¢‘æ¬¡ï¼‰
        edge_stats_loc = net_df_loc_act.groupby(['location', 'activity_type'])['loc_total_freq'].sum().reset_index()
        edge_stats_loc.columns = ['location', 'activity_type', 'edge_freq']
        for _, row in edge_stats_loc.iterrows():
            loc_id = f"loc_act_{row['location']}"
            act_id = f"act_loc_{row['activity_type']}"
            edge_width = 2 + (row['edge_freq'] / edge_stats_loc['edge_freq'].max()) * 6  # ç²—ç»†éšé¢‘æ¬¡å˜åŒ–
            # Hoveræç¤ºï¼šåœ°ç‚¹-æ´»åŠ¨+é¢‘æ¬¡+æ¶‰åŠç« å›
            related_chapters = sorted(net_df_loc_act[
                (net_df_loc_act['location'] == row['location']) & 
                (net_df_loc_act['activity_type'] == row['activity_type'])
            ]['chapter'].unique())
            chapter_str = ", ".join(map(str, related_chapters))
            net_loc_act.add_edge(
                loc_id, act_id,
                color="#7f8c8d",  # ç°è‰²è¾¹
                width=edge_width,
                title=f"{row['location']} â†” {row['activity_type']}\né¢‘æ¬¡ï¼š{row['edge_freq']}æ¬¡\nç« å›ï¼š{chapter_str}"
            )
        
        # â‘£ å¸ƒå±€ä¸äº¤äº’è®¾ç½®
        net_loc_act.barnes_hut(gravity=-2500, spring_length=200)  # è°ƒæ•´å¸ƒå±€ï¼Œé¿å…èŠ‚ç‚¹é‡å 
        net_loc_act.show_buttons(["physics", "nodes", "edges"])  # ä¿ç•™è°ƒèŠ‚æŒ‰é’®
        
        st.subheader("æ´»åŠ¨-åœ°ç‚¹å…³è”å›¾è°±")
        # â‘¤ ä¸´æ—¶æ–‡ä»¶åŠ è½½ï¼ˆé¿å…æœ¬åœ°è·¯å¾„é—®é¢˜ï¼‰
        with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as f:
            net_loc_act.save_graph(f.name)
            with open(f.name, "r", encoding="utf-8") as f_html:
                components.html(f_html.read(), width="100%", height=600, scrolling=False)
        
        # â‘¥ å›¾è°±è¯´æ˜
        st.caption("æ·±è“è‰²=åœ°ç‚¹ï¼ˆå¤§å°=æ€»å‡ºç°æ¬¡æ•°ï¼‰" \
        "æµ…è“è‰²=æ´»åŠ¨ç±»å‹ï¼ˆå¤§å°=å…³è”åœ°ç‚¹æ•°ï¼‰" \
        "è¾¹è¶Šç²—=æ´»åŠ¨åœ¨è¯¥åœ°ç‚¹é¢‘æ¬¡è¶Šé«˜")

# ---------------------- æ ‡ç­¾é¡µ3ï¼šåœ°ç‚¹-äººç‰©-æ´»åŠ¨ç»Ÿè®¡çœ‹æ¿ ----------------------
with tab3:
    st.title("ã€Šå„’æ—å¤–å²ã€‹åœ°ç‚¹-äººç‰©-æ´»åŠ¨ç±»å‹ç»Ÿè®¡çœ‹æ¿")
    
    # æ ¸å¿ƒåŠŸèƒ½ï¼šå¤šç»´åº¦æ•°æ®ç»Ÿè®¡ä¸å¯¼å‡º
    st.sidebar.header("ç»Ÿè®¡ç­›é€‰æ¡ä»¶")
    # 1. ç»Ÿè®¡ç»´åº¦é€‰æ‹©
    stat_dimension = st.sidebar.radio(
        "é€‰æ‹©ç»Ÿè®¡ç»´åº¦",
        ["æŒ‰åœ°ç‚¹ç»Ÿè®¡", "æŒ‰äººç‰©ç»Ÿè®¡", "æŒ‰æ´»åŠ¨ç±»å‹ç»Ÿè®¡"]
    )
    # 2. ç« å›èŒƒå›´ç­›é€‰ï¼ˆç¡®ä¿min_chapter/max_chapterå·²æå‰å®šä¹‰ï¼Œæ¥è‡ªdf['chapter']çš„æœ€å€¼ï¼‰
    min_chapter = int(df['chapter'].min())
    max_chapter = int(df['chapter'].max())
    selected_chapters_stat = st.sidebar.slider(
        "é€‰æ‹©ç« å›èŒƒå›´", 
        min_value=min_chapter, 
        max_value=max_chapter, 
        value=(min_chapter, max_chapter),
        key="stat_chapter_slider" 
    )
    
    # åº”ç”¨ç« å›ç­›é€‰ï¼šå…ˆç­›é€‰æŒ‡å®šç« å›èŒƒå›´çš„æ•°æ®
    stat_df = df[
        (df['chapter'] >= selected_chapters_stat[0]) &
        (df['chapter'] <= selected_chapters_stat[1])
    ].copy()  # å¤åˆ¶æ•°æ®ï¼Œé¿å…ä¿®æ”¹åŸdf
    
    # æŒ‰ä¸åŒç»´åº¦ç”Ÿæˆç»Ÿè®¡è¡¨æ ¼
    if stat_dimension == "æŒ‰åœ°ç‚¹ç»Ÿè®¡":
        st.subheader(f"æŒ‰åœ°ç‚¹ç»Ÿè®¡ï¼ˆç¬¬{selected_chapters_stat[0]}-{selected_chapters_stat[1]}å›ï¼‰")
        
        # ---------------------- æ ¸å¿ƒä¿®æ”¹ï¼šç»Ÿè®¡â€œåœ°ç‚¹é¦–æ¬¡å‡ºç°åœ¨ç« å›ä¸­çš„æ€»æ¬¡æ•°â€ ----------------------
        # 1. æŒ‰â€œåœ°ç‚¹+ç« å›â€åˆ†ç»„ï¼Œå–æ¯ç»„é¦–æ¬¡å‡ºç°çš„è¡Œï¼ˆç¡®ä¿æ¯ä¸ªåœ°ç‚¹åœ¨æ¯ä¸ªç« å›åªç»Ÿè®¡1æ¬¡ï¼‰
        loc_chapter_first = stat_df.groupby(['location', 'chapter']).first().reset_index()
        # 2. æŒ‰â€œåœ°ç‚¹â€åˆ†ç»„ï¼Œæ±‚å’Œé¦–æ¬¡å‡ºç°çš„loc_total_freqï¼ˆå¾—åˆ°æ¯ä¸ªåœ°ç‚¹çš„æ€»æ¬¡æ•°ï¼‰
        loc_total_freq = loc_chapter_first.groupby('location')['loc_total_freq'].sum().reset_index()
        loc_total_freq.columns = ['location', 'æ€»å‡ºç°æ¬¡æ•°']  # é‡å‘½ååˆ—ï¼Œä¾¿äºåç»­åˆå¹¶
        
        # 3. ç»Ÿè®¡å…¶ä»–ç»´åº¦ä¿¡æ¯ï¼ˆæ¶‰åŠç« å›ã€å…³è”äººç‰©ã€æ´»åŠ¨ç±»å‹ç­‰ï¼‰
        loc_other_stats = stat_df.groupby('location').agg({
            # æ¶‰åŠç« å›ï¼šå»é‡åæ ¼å¼åŒ–ä¸ºâ€œXå›ï¼ˆå›æ¬¡1, å›æ¬¡2ï¼‰â€
            'chapter': lambda x: f"{len(set(x))}å›ï¼ˆ{', '.join(map(str, sorted(set(x))))}ï¼‰",
            # å…³è”äººç‰©ï¼šæ‹†åˆ†å¤šäººç‰©ã€å»é‡ååˆå¹¶
            'characters': lambda x: ', '.join(list(set([
                c.strip() for chars in x.dropna() for c in chars.split('ï¼Œ')
            ])) or ['æ— ']),
            # æ´»åŠ¨ç±»å‹ï¼šç»Ÿè®¡æ¯ç§æ´»åŠ¨çš„æ¬¡æ•°ï¼Œç”Ÿæˆå­—å…¸
            'activity_type': lambda x: x.value_counts().to_dict(),
            # æƒ…èŠ‚ç¤ºä¾‹ï¼šå–ç¬¬ä¸€æ¡éç©ºæƒ…èŠ‚çš„å‰80å­—
            'plot_summary': lambda x: next((p[:80] + "..." for p in x.dropna() if p), "æ— ç›¸å…³æƒ…èŠ‚")
        }).reset_index()
        
        # 4. åˆå¹¶â€œæ€»å‡ºç°æ¬¡æ•°â€ä¸å…¶ä»–ç»Ÿè®¡ä¿¡æ¯ï¼ˆé€šè¿‡locationå…³è”ï¼‰
        loc_stat_table = loc_other_stats.merge(loc_total_freq, on='location', how='left')
        
        # ---------------------- åŸæœ‰é€»è¾‘ï¼šæ ¼å¼åŒ–æ´»åŠ¨ç±»å‹ç»Ÿè®¡ ----------------------
        loc_stat_table['æ´»åŠ¨ç±»å‹ç»Ÿè®¡'] = loc_stat_table['activity_type'].apply(
            lambda x: ", ".join([f"{act}ï¼ˆ{freq}æ¬¡ï¼‰" for act, freq in x.items()])
        )
        
        # ---------------------- æ˜¾ç¤ºè¡¨æ ¼ï¼šè°ƒæ•´åˆ—é¡ºåºï¼Œç¡®ä¿â€œæ€»å‡ºç°æ¬¡æ•°â€åœ¨æ˜¾çœ¼ä½ç½® ----------------------
        display_table = loc_stat_table[
            ['location', 'æ€»å‡ºç°æ¬¡æ•°', 'chapter', 'characters', 'æ´»åŠ¨ç±»å‹ç»Ÿè®¡', 'plot_summary']
        ].rename(columns={
            'location': 'åœ°ç‚¹',
            'chapter': 'æ¶‰åŠç« å›',
            'characters': 'å…³è”äººç‰©',
            'plot_summary': 'æƒ…èŠ‚ç¤ºä¾‹'
        })
        st.dataframe(display_table, height=400)
    
    elif stat_dimension == "æŒ‰äººç‰©ç»Ÿè®¡":
        # æŒ‰äººç‰©ç»Ÿè®¡ï¼šé€»è¾‘ä¸å˜ï¼ˆå¦‚éœ€è°ƒæ•´å¯å‚è€ƒåœ°ç‚¹ç»Ÿè®¡çš„ä¿®æ”¹æ€è·¯ï¼‰
        st.subheader(f"æŒ‰äººç‰©ç»Ÿè®¡ï¼ˆç¬¬{selected_chapters_stat[0]}-{selected_chapters_stat[1]}å›ï¼‰")
        char_stat_list = []
        for _, row in stat_df.iterrows():
            # æ‹†åˆ†å¤šäººç‰©ï¼ˆå¤„ç†â€œï¼Œâ€åˆ†éš”çš„æƒ…å†µï¼‰
            chars = [c.strip() for c in row['characters'].split('ï¼Œ')] if pd.notna(row['characters']) else []
            for char in chars:
                char_stat_list.append({
                    'äººç‰©': char,
                    'æ¶‰åŠç« å›': row['chapter'],
                    'å…³è”åœ°ç‚¹': row['location'],
                    'å‚ä¸æ´»åŠ¨': row['activity_type'],
                    'æƒ…èŠ‚': row['plot_summary'][:60] + "..." if pd.notna(row['plot_summary']) else "æ— ç›¸å…³æƒ…èŠ‚"
                })
        # å»é‡åæŒ‰äººç‰©åˆ†ç»„ç»Ÿè®¡
        char_stat_df = pd.DataFrame(char_stat_list).drop_duplicates()
        char_stat_table = char_stat_df.groupby('äººç‰©').agg({
            'æ¶‰åŠç« å›': lambda x: f"{len(set(x))}å›ï¼ˆ{', '.join(map(str, sorted(set(x))))}ï¼‰",
            'å…³è”åœ°ç‚¹': lambda x: ', '.join(list(set(x)) or ['æ— ']),
            'å‚ä¸æ´»åŠ¨': lambda x: x.value_counts().to_dict(),
            'æƒ…èŠ‚': lambda x: x.iloc[0] if not x.empty else "æ— ç›¸å…³æƒ…èŠ‚"
        }).reset_index()
        # æ ¼å¼åŒ–æ´»åŠ¨ç»Ÿè®¡
        char_stat_table['å‚ä¸æ´»åŠ¨ç»Ÿè®¡'] = char_stat_table['å‚ä¸æ´»åŠ¨'].apply(
            lambda x: ", ".join([f"{act}ï¼ˆ{freq}æ¬¡ï¼‰" for act, freq in x.items()])
        )
        # æ˜¾ç¤ºè¡¨æ ¼
        display_table = char_stat_table[['äººç‰©', 'æ¶‰åŠç« å›', 'å…³è”åœ°ç‚¹', 'å‚ä¸æ´»åŠ¨ç»Ÿè®¡', 'æƒ…èŠ‚']]
        st.dataframe(display_table, height=400)
    
    else:  # æŒ‰æ´»åŠ¨ç±»å‹ç»Ÿè®¡ï¼šé€»è¾‘ä¸å˜
        st.subheader(f"æŒ‰æ´»åŠ¨ç±»å‹ç»Ÿè®¡ï¼ˆç¬¬{selected_chapters_stat[0]}-{selected_chapters_stat[1]}å›ï¼‰")
        # ç»Ÿè®¡æ´»åŠ¨ç±»å‹çš„åŸºç¡€ä¿¡æ¯
        act_stat_table = stat_df.groupby('activity_type').agg({
            'chapter': lambda x: f"{len(set(x))}å›ï¼ˆ{', '.join(map(str, sorted(set(x))))}ï¼‰",
            'location': lambda x: ', '.join(list(set(x)) or ['æ— ']),
            'characters': lambda x: ', '.join(list(set([
                c.strip() for chars in x.dropna() for c in chars.split('ï¼Œ')
            ])) or ['æ— ']),
            'plot_summary': lambda x: next((p[:80] + "..." for p in x.dropna() if p), "æ— ç›¸å…³æƒ…èŠ‚")
        }).reset_index()
        # è®¡ç®—æ´»åŠ¨æ€»æ¬¡æ•°ï¼ˆå»é‡â€œæ´»åŠ¨ç±»å‹+ç« å›â€ï¼Œé¿å…é‡å¤ç»Ÿè®¡ï¼‰
        act_freq = stat_df.groupby(['activity_type', 'chapter']).first().reset_index()
        act_freq = act_freq['activity_type'].value_counts().reset_index()
        act_freq.columns = ['activity_type', 'æ´»åŠ¨æ€»æ¬¡æ•°']
        # åˆå¹¶æ€»æ¬¡æ•°ä¸åŸºç¡€ä¿¡æ¯
        act_stat_table = act_stat_table.merge(act_freq, on='activity_type', how='left')
        # æ˜¾ç¤ºè¡¨æ ¼
        display_table = act_stat_table[
            ['activity_type', 'æ´»åŠ¨æ€»æ¬¡æ•°', 'chapter', 'location', 'characters', 'plot_summary']
        ].rename(columns={
            'activity_type': 'æ´»åŠ¨ç±»å‹',
            'chapter': 'æ¶‰åŠç« å›',
            'location': 'å…³è”åœ°ç‚¹',
            'characters': 'å…³è”äººç‰©',
            'plot_summary': 'æƒ…èŠ‚ç¤ºä¾‹'
        })
        st.dataframe(display_table, height=400)
    
    # ---------------------- æ•°æ®å¯¼å‡ºåŠŸèƒ½ï¼šé€‚é…ä¿®æ”¹åçš„â€œæ€»å‡ºç°æ¬¡æ•°â€åˆ— ----------------------
    st.subheader("æ•°æ®å¯¼å‡º")
    export_format = st.selectbox("é€‰æ‹©å¯¼å‡ºæ ¼å¼", ["CSV", "Excel"])
    if st.button(f"å¯¼å‡ºå½“å‰ç»Ÿè®¡è¡¨æ ¼ï¼ˆ{export_format}ï¼‰"):
        # ç¡®ä¿å¯¼å‡ºçš„è¡¨æ ¼ä¸æ˜¾ç¤ºçš„è¡¨æ ¼ä¸€è‡´
        export_table = display_table.copy()
        # å¤„ç†å¯¼å‡ºè·¯å¾„ï¼šæ›¿æ¢ä¸ºä½ ç”µè„‘ä¸Šçš„å®é™…è·¯å¾„ï¼ˆå¦‚æ¡Œé¢ï¼‰ï¼Œé¿å…/mntç›®å½•ä¸å­˜åœ¨
        export_path = f"/Users/ye/Desktop/å„’æ—å¤–å²ç»Ÿè®¡ç»“æœ.{export_format.lower()}"
        
        try:
            if export_format == "CSV":
                export_table.to_csv(export_path, index=False, encoding='utf-8-sig')
            else:
                with pd.ExcelWriter(export_path, engine='openpyxl') as writer:
                    export_table.to_excel(writer, sheet_name=stat_dimension, index=False)
            # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯å¹¶æä¾›ä¸‹è½½æŒ‰é’®
            st.success(f"{export_format}æ–‡ä»¶å·²ç”Ÿæˆï¼")
            with open(export_path, 'rb') as f:
                st.download_button(
                    label=f"ç‚¹å‡»ä¸‹è½½{export_format}æ–‡ä»¶",
                    data=f,
                    file_name=f"å„’æ—å¤–å²_{stat_dimension}_{selected_chapters_stat[0]}-{selected_chapters_stat[1]}å›.{export_format.lower()}",
                    mime="text/csv" if export_format == "CSV" else "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        except Exception as e:
            st.error(f"å¯¼å‡ºå¤±è´¥ï¼š{str(e)}")
            st.info("å»ºè®®æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œæˆ–å°è¯•æ›´æ¢å¯¼å‡ºè·¯å¾„ï¼ˆå¦‚æ¡Œé¢ï¼‰")
